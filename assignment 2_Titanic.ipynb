{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.tree as tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Titanic survival data set\n",
    "data = pd.read_csv('train.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I followed all data preprocessing steps in this article.\n",
    "https://medium.com/i-like-big-data-and-i-cannot-lie/how-i-scored-in-the-top-9-of-kaggles-titanic-machine-learning-challenge-243b5f45c8e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RangeIndex tells that there are 891 entries, but Age, Cabin, and Embarked have fewer than that, suggesting that these 3 columns have null/missing values. \n",
    "\n",
    "To  fix missing values in these variables:\n",
    "- Missing age: Data is grouped by a passenger’s sex, class, and title, fill the missing age with then median age by each group.\n",
    "- Missing Cabin: Fill Cabin with \"U\" for unknown.\n",
    "- Missing Embarked: Fill with the most frequent point of embarkment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new feature to extract title names from the column of \"Name\"\n",
    "data['Title'] = data.Name.apply(lambda name: name.split(',')[1].split('.')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr         517\n",
      "Miss       184\n",
      "Mrs        127\n",
      "Master      40\n",
      "Officer     18\n",
      "Royalty      5\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "normalized_titles = {\n",
    "    \"Capt\":       \"Officer\",\n",
    "    \"Col\":        \"Officer\",\n",
    "    \"Major\":      \"Officer\",\n",
    "    \"Jonkheer\":   \"Royalty\",\n",
    "    \"Don\":        \"Royalty\",\n",
    "    \"Sir\" :       \"Royalty\",\n",
    "    \"Dr\":         \"Officer\",\n",
    "    \"Rev\":        \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Dona\":       \"Royalty\",\n",
    "    \"Mme\":        \"Mrs\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Ms\":         \"Mrs\",\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Lady\" :      \"Royalty\"\n",
    "}\n",
    "\n",
    "# map the normalized titles to the current titles \n",
    "data.Title = data.Title.map(normalized_titles)\n",
    "# view value counts for the normalized titles\n",
    "print(data.Title.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Pclass  Title  \n",
       "female  1       Miss       30.0\n",
       "                Mrs        40.0\n",
       "                Officer    49.0\n",
       "                Royalty    40.5\n",
       "        2       Miss       24.0\n",
       "                Mrs        31.5\n",
       "        3       Miss       18.0\n",
       "                Mrs        31.0\n",
       "male    1       Master      4.0\n",
       "                Mr         40.0\n",
       "                Officer    51.0\n",
       "                Royalty    40.0\n",
       "        2       Master      1.0\n",
       "                Mr         31.0\n",
       "                Officer    46.5\n",
       "        3       Master      4.0\n",
       "                Mr         26.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by Sex, Pclass, and Title \n",
    "grouped = data.groupby(['Sex','Pclass', 'Title'])  \n",
    "# view the median Age by the grouped features \n",
    "grouped.Age.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply the grouped median value on the Age NaN\n",
    "data.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          891 non-null object\n",
      "Embarked       891 non-null object\n",
      "Title          891 non-null object\n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# fill Cabin NaN with U for unknown\n",
    "data.Cabin = data.Cabin.fillna('U')\n",
    "# find most frequent Embarked value and store in variable\n",
    "most_embarked = data.Embarked.value_counts().index[0]\n",
    "\n",
    "# fill NaN with most_embarked value\n",
    "data.Embarked = data.Embarked.fillna(most_embarked)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the steps in this article, two new features are created: Family size per passenger.The assumption is that it is more difficult for a larger family to secure a spot on a life boat, compared to a smaller size family. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# size of families (including the passenger)\n",
    "data['FamilySize'] = data.Parch + data.SibSp + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another feature is the Cabin feature. The first letter of the Cabin is extracted to represent the Cabin feature. A Kaggle discussion mentions that the first letter of the cabin indicates deck.(https://www.kaggle.com/c/titanic/discussion/4693) Also, pclass roughly matches the deck - that is, first class has the top decks (A-E), second class (D-F), and thrid class (E-G). The assumption is that passengers with a higher deck/pclass have a higher possibility to survive, because they are closer to lifeboats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map first letter of cabin to itself\n",
    "data.Cabin = data.Cabin.map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          891 non-null object\n",
      "Embarked       891 non-null object\n",
      "Title          891 non-null object\n",
      "FamilySize     891 non-null int64\n",
      "dtypes: float64(2), int64(6), object(6)\n",
      "memory usage: 97.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Cabin_U</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex   Age  SibSp  Parch     Fare  FamilySize  \\\n",
       "0            1         0    0  22.0      1      0   7.2500           2   \n",
       "1            2         1    1  38.0      1      0  71.2833           2   \n",
       "2            3         1    1  26.0      0      0   7.9250           1   \n",
       "3            4         1    1  35.0      1      0  53.1000           2   \n",
       "4            5         0    0  35.0      0      0   8.0500           1   \n",
       "\n",
       "   Pclass_1  Pclass_2     ...      Cabin_C  Cabin_D  Cabin_E  Cabin_F  \\\n",
       "0         0         0     ...            0        0        0        0   \n",
       "1         1         0     ...            1        0        0        0   \n",
       "2         0         0     ...            0        0        0        0   \n",
       "3         1         0     ...            1        0        0        0   \n",
       "4         0         0     ...            0        0        0        0   \n",
       "\n",
       "   Cabin_G  Cabin_T  Cabin_U  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0        0        1           0           0           1  \n",
       "1        0        0        0           1           0           0  \n",
       "2        0        0        1           0           0           1  \n",
       "3        0        0        0           0           0           1  \n",
       "4        0        0        1           0           0           1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical features into dummy variables.\n",
    "# Convert the male and female groups to integer form\n",
    "data.Sex = data.Sex.map({\"male\": 0, \"female\":1})\n",
    "# create dummy variables for categorical features\n",
    "pclass_dummies = pd.get_dummies(data.Pclass, prefix=\"Pclass\")\n",
    "title_dummies = pd.get_dummies(data.Title, prefix=\"Title\")\n",
    "cabin_dummies = pd.get_dummies(data.Cabin, prefix=\"Cabin\")\n",
    "embarked_dummies = pd.get_dummies(data.Embarked, prefix=\"Embarked\")\n",
    "# concatenate dummy columns with main dataset\n",
    "data_dummies = pd.concat([data, pclass_dummies, title_dummies, cabin_dummies, embarked_dummies], axis=1)\n",
    "\n",
    "# drop categorical fields\n",
    "data_dummies.drop(['Pclass', 'Title', 'Cabin', 'Embarked', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "data_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 29 columns):\n",
      "PassengerId      891 non-null int64\n",
      "Survived         891 non-null int64\n",
      "Sex              891 non-null int64\n",
      "Age              891 non-null float64\n",
      "SibSp            891 non-null int64\n",
      "Parch            891 non-null int64\n",
      "Fare             891 non-null float64\n",
      "FamilySize       891 non-null int64\n",
      "Pclass_1         891 non-null uint8\n",
      "Pclass_2         891 non-null uint8\n",
      "Pclass_3         891 non-null uint8\n",
      "Title_Master     891 non-null uint8\n",
      "Title_Miss       891 non-null uint8\n",
      "Title_Mr         891 non-null uint8\n",
      "Title_Mrs        891 non-null uint8\n",
      "Title_Officer    891 non-null uint8\n",
      "Title_Royalty    891 non-null uint8\n",
      "Cabin_A          891 non-null uint8\n",
      "Cabin_B          891 non-null uint8\n",
      "Cabin_C          891 non-null uint8\n",
      "Cabin_D          891 non-null uint8\n",
      "Cabin_E          891 non-null uint8\n",
      "Cabin_F          891 non-null uint8\n",
      "Cabin_G          891 non-null uint8\n",
      "Cabin_T          891 non-null uint8\n",
      "Cabin_U          891 non-null uint8\n",
      "Embarked_C       891 non-null uint8\n",
      "Embarked_Q       891 non-null uint8\n",
      "Embarked_S       891 non-null uint8\n",
      "dtypes: float64(2), int64(6), uint8(21)\n",
      "memory usage: 74.0 KB\n"
     ]
    }
   ],
   "source": [
    "data_dummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdf=data_dummies[['Sex','Age','SibSp','Parch','Fare','FamilySize','Pclass_1','Pclass_2','Pclass_3',\n",
    "                'Title_Master','Title_Miss','Title_Mr','Title_Mrs','Title_Officer','Title_Royalty','Cabin_A','Cabin_B',         \n",
    "                'Cabin_C','Cabin_D','Cabin_E','Cabin_F','Cabin_G','Cabin_T','Cabin_U','Embarked_C','Embarked_Q','Embarked_S']]\n",
    "Ydf=data_dummies[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=Xdf.values\n",
    "Y=Ydf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set in Titanic survival classification model has 668 samples.\n",
      "Testing set in Titanic survival classification model has 223 samples.\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and  test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n",
    "print (\"Training set in Titanic survival classification model has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set in Titanic survival classification model has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (train set, baseline - no cross validation): 0.846\n",
      "Model Training Time (s):   0.24109\n",
      "Model Prediction Time (s): 0.00030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks\n",
    "# Baseline (no pruning)\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "neuraln0 = MLPClassifier(random_state=1)\n",
    "neuraln0.fit(X_train, y_train.ravel())\n",
    "end_time = timeit.default_timer()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "Y_pred0 = neuraln0.predict(X_test)\n",
    "end_time = timeit.default_timer()\n",
    "predict_time = end_time - start_time\n",
    "\n",
    "acctrain_neuraln0 = round(neuraln0.score(X_train, y_train), 3)\n",
    "print('Accuracy score (train set, baseline - no cross validation):', acctrain_neuraln0)\n",
    "print(\"Model Training Time (s):   \"+\"{:.5f}\".format(training_time))\n",
    "print(\"Model Prediction Time (s): \"+\"{:.5f}\\n\".format(pred_time))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mlrose\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "#from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:  1.8min finished\n",
      "C:\\Users\\E015919\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time total:108.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E015919\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Class MLPClassifier implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation.\n",
    "# This has been done in Assignment 1. Based on reviewer's comments, I further tried different activation function and hidden layer size.\n",
    "# Also, Multi-layer Perceptron is sensitive to feature scaling, so I did it.\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import timeit\n",
    "import time\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "\n",
    "MLP = MLPClassifier(random_state=1)\n",
    "mlp_param_grid = {'hidden_layer_sizes' : [(5,),(10,),(15,),(20,)], \n",
    "                  'learning_rate_init': [0.0001,0.001,0.01],\n",
    "                  'activation': ['relu', 'logistic'],\n",
    "                  'max_iter':[200,300,400,600]}\n",
    "\n",
    "gsMLP = GridSearchCV(MLP,param_grid = mlp_param_grid, cv=5, scoring='accuracy',n_jobs=-1,verbose=1)\n",
    "gsMLP.fit(X_train_scaled,y_train)\n",
    "MLP_best = gsMLP.best_estimator_\n",
    "\n",
    "#gsMLP.best_score_\n",
    "\n",
    "print(\"process time total:{:.2f} seconds\".format(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.8383233532934131\n",
      "best param: {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001, 'max_iter': 300}\n"
     ]
    }
   ],
   "source": [
    "print(\"best score: %s\" % gsMLP.best_score_)\n",
    "print(\"best param: %s\" % gsMLP.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E015919\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Time (s):   0.53842\n",
      "Accuracy score (test set, pruned): 0.825\n",
      "Accuracy score (train set, pruned): 0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E015919\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Re-run NN with the best parameters reported in Grid Search\n",
    "\n",
    "nn1 = MLPClassifier(max_iter=300,activation='relu',\n",
    "                    learning_rate_init=0.001,\n",
    "                    #solver='lbfgs',\n",
    "                    hidden_layer_sizes=[10,],random_state=1)\n",
    "\n",
    "# Training\n",
    "start_time = timeit.default_timer()\n",
    "nn1.fit(X_train_scaled, y_train)\n",
    "end_time = timeit.default_timer()\n",
    "training_time = end_time - start_time\n",
    "print(\"Model Training Time (s):   \"+\"{:.5f}\".format(training_time))\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred_mlp = nn1.predict(X_test_scaled)\n",
    "y_test_accuracy_mlp = round(accuracy_score(y_test, y_test_pred_mlp),3)\n",
    "print('Accuracy score (test set, pruned):', y_test_accuracy_mlp)\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred_mlp = nn1.predict(X_train_scaled)\n",
    "y_train_accuracy_mlp = round(accuracy_score(y_train, y_train_pred_mlp),3)\n",
    "print('Accuracy score (train set, pruned):',y_train_accuracy_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Time - NN1-GA (s):   77.18175\n",
      "Accuracy score (test set, pruned): 0.78\n",
      "Accuracy score (train set, pruned): 0.817\n"
     ]
    }
   ],
   "source": [
    "nn1_ga = mlrose.NeuralNetwork(hidden_nodes = [10], activation = 'relu', algorithm = 'genetic_alg', \n",
    "                           bias = True,  is_classifier = True, \n",
    "                           #learning_rate=0.1, \n",
    "                           early_stopping=True, \n",
    "                           #clip_max=5, \n",
    "                           max_attempts =500, max_iters=300)\n",
    "\n",
    "# Training\n",
    "start_time = timeit.default_timer()\n",
    "nn1_ga.fit(X_train_scaled, y_train)\n",
    "end_time = timeit.default_timer()\n",
    "training_time = end_time - start_time\n",
    "print(\"Model Training Time - NN1-GA (s):   \"+\"{:.5f}\".format(training_time))\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred_nn1ga = nn1_ga.predict(X_test_scaled)\n",
    "y_test_accuracy_nn1ga = round(accuracy_score(y_test, y_test_pred_nn1ga),3)\n",
    "print('Accuracy score (test set, pruned):', y_test_accuracy_nn1ga)\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred_nn1ga = nn1_ga.predict(X_train_scaled)\n",
    "y_train_accuracy_nn1ga = round(accuracy_score(y_train, y_train_pred_nn1ga),3)\n",
    "print('Accuracy score (train set, pruned):',y_train_accuracy_nn1ga)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
